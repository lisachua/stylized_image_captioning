{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and combine humor and romantic captions from FlickrStyle7k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = pickle.load(open( \"data/FlickrStyle_v0.9/humor/train.p\", \"rb\" ) )\n",
    "text = pd.read_csv(\"data/FlickrStyle_v0.9/humor/funny_train.txt\", encoding= 'unicode_escape', names=['caption'])\n",
    "captions = list(text.caption)\n",
    "df_funny = pd.DataFrame(zip(img_id, captions), columns=['img_id', 'funny_caption'])\n",
    "\n",
    "img_id = pickle.load(open( \"data/FlickrStyle_v0.9/romantic/train.p\", \"rb\" ) )\n",
    "text = pd.read_csv(\"data/FlickrStyle_v0.9/romantic/romantic_train.txt\", encoding= 'unicode_escape', names=['caption'])\n",
    "captions = list(text.caption)\n",
    "df_romantic = pd.DataFrame(zip(img_id, captions), columns=['img_id', 'romantic_caption'])\n",
    "\n",
    "df_stylized = df_funny.merge(df_romantic, on='img_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>funny_caption</th>\n",
       "      <th>romantic_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2513260012_03d33305cf.jpg</td>\n",
       "      <td>two dogs chase each other across the snowy ground in search of gold nuggets .</td>\n",
       "      <td>two dogs in love are playing together in the snow with full joy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2903617548_d3e38d7f88.jpg</td>\n",
       "      <td>a little girl plays croquet next to a truck to amuse her dad .</td>\n",
       "      <td>the child is playing croquette by the truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3338291921_fe7ae0c8f8.jpg</td>\n",
       "      <td>a dog with something pink in its mouth is looking forward to an adventure .</td>\n",
       "      <td>a dog is holding a shirt searching for his lost love in the snow .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>488416045_1c6d903fe0.jpg</td>\n",
       "      <td>a dog walks on the sand near the water</td>\n",
       "      <td>a brown dog is running along a beach towards his loving master .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2644326817_8f45080b87.jpg</td>\n",
       "      <td>a dog is surprised by a red frisbee flying in the air .</td>\n",
       "      <td>a dog drops a red disc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      img_id  \\\n",
       "0  2513260012_03d33305cf.jpg   \n",
       "1  2903617548_d3e38d7f88.jpg   \n",
       "2  3338291921_fe7ae0c8f8.jpg   \n",
       "3  488416045_1c6d903fe0.jpg    \n",
       "4  2644326817_8f45080b87.jpg   \n",
       "\n",
       "                                                                   funny_caption  \\\n",
       "0  two dogs chase each other across the snowy ground in search of gold nuggets .   \n",
       "1  a little girl plays croquet next to a truck to amuse her dad .                  \n",
       "2  a dog with something pink in its mouth is looking forward to an adventure .     \n",
       "3  a dog walks on the sand near the water                                          \n",
       "4  a dog is surprised by a red frisbee flying in the air .                         \n",
       "\n",
       "                                                     romantic_caption  \n",
       "0  two dogs in love are playing together in the snow with full joy .   \n",
       "1  the child is playing croquette by the truck                         \n",
       "2  a dog is holding a shirt searching for his lost love in the snow .  \n",
       "3  a brown dog is running along a beach towards his loving master .    \n",
       "4  a dog drops a red disc                                              "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stylized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Flickr8k to match FlickrStyle7k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr8k_filename = \"data/Flickr8k_text/Flickr8k.token.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Flickr8k(filename):\n",
    "    token = pd.read_csv(filename, delimiter='\\n', encoding= 'unicode_escape', names=['line'])\n",
    "    # parse lines into imd_id, cap_id, caption\n",
    "    new = token['line'].str.split('#', n=1, expand=True)\n",
    "    new2 = new[1].str.split('\\t', n=1, expand=True)\n",
    "    token['img_id'] = new[0]\n",
    "    token['cap_id'] = new2[0]\n",
    "    token['caption'] = new2[1]\n",
    "    return token.drop(['line'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_Flickr8k_to_7k(flickr8k, flickr7k):\n",
    "    return flickr8k.merge(flickr7k, on='img_id', how='inner').drop(['funny_caption', 'romantic_caption'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = load_Flickr8k(flickr8k_filename)\n",
    "df_factual = filter_Flickr8k_to_7k(token, df_stylized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_factual.img_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([tuple(x) for x in df_stylized[['funny_caption', 'romantic_caption']].to_numpy()])\n",
    "y = df_stylized[['img_id']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['two dogs chase each other across the snowy ground in search of gold nuggets .',\n",
       "        'two dogs in love are playing together in the snow with full joy .'],\n",
       "       dtype='<U141'), array(['2513260012_03d33305cf.jpg'], dtype=object))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vocab for all captions, using pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'large',\n",
       " 'brown',\n",
       " 'dog',\n",
       " 'is',\n",
       " 'sticking',\n",
       " 'his',\n",
       " 'face',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sprinkler',\n",
       " 'to',\n",
       " 'catch',\n",
       " 'it',\n",
       " '.',\n",
       " 'dog',\n",
       " 'slurps',\n",
       " 'water',\n",
       " 'from',\n",
       " 'sprinkler',\n",
       " 'on',\n",
       " 'the',\n",
       " 'grass',\n",
       " 'leaving',\n",
       " 'some',\n",
       " 'for',\n",
       " 'the',\n",
       " 'lawn',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tok(X_train[0][0]+\" \"+ X_train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile=\"data/glove.6B.50d.txt\"):\n",
    "    \"\"\" Loads word vectors into a dictionary.\"\"\"\n",
    "    f = open(gloveFile,'r')\n",
    "    word_vecs = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        word_vecs[word] = np.array([float(val) for val in splitLine[1:]])\n",
    "    return word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(content):\n",
    "    \"\"\"Computes Dict of counts of words.\n",
    "    \n",
    "    Computes the number of times a word is on a document.\n",
    "    \"\"\"\n",
    "    vocab = defaultdict(float)\n",
    "    for line in content:\n",
    "        words = set(spacy_tok(line[0]+\" \"+line[1]))\n",
    "        for word in words:\n",
    "            vocab[word] += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = loadGloveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 7590\n"
     ]
    }
   ],
   "source": [
    "word_count = get_vocab(X_train)\n",
    "print(len(word_vecs.keys()), len(word_count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_rare_words(word_vecs, word_count, min_df=4):\n",
    "    \"\"\" Deletes rare words from word_count\n",
    "    \n",
    "    Deletes words from word_count if they are not in word_vecs\n",
    "    and don't have at least min_df occurrencies in word_count.\n",
    "    \"\"\"\n",
    "    words_delete = []\n",
    "    for word in word_count:\n",
    "        if word_count[word] < min_df and word not in word_vecs:\n",
    "            words_delete.append(word)\n",
    "    for word in words_delete: word_count.pop(word)\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7241\n"
     ]
    }
   ],
   "source": [
    "word_count = delete_rare_words(word_vecs, word_count)\n",
    "print(len(word_count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(word_vecs, word_count, min_df=4, emb_size=50):\n",
    "    \"\"\"Creates embedding matrix from word vectors. \"\"\"\n",
    "    word_count = delete_rare_words(word_vecs, word_count, min_df)\n",
    "    V = len(word_count.keys()) + 2\n",
    "    vocab2index = {}\n",
    "    W = np.zeros((V, emb_size), dtype=\"float32\")\n",
    "    vocab = [\"\", \"UNK\"]\n",
    "    # adding a vector for padding\n",
    "    W[0] = np.zeros(emb_size, dtype='float32')\n",
    "    # adding a vector for rare words \n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size)\n",
    "    vocab2index[\"UNK\"] = 1\n",
    "    i = 2\n",
    "    for word in word_count:\n",
    "        if word in word_vecs:\n",
    "            W[i] = word_vecs[word]\n",
    "            vocab2index[word] = i\n",
    "            vocab.append(word)\n",
    "            i += 1\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "            vocab2index[word] = i\n",
    "            vocab.append(word)\n",
    "            i += 1   \n",
    "    return W, np.array(vocab), vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weight, vocab, vocab2index = create_embedding_matrix(word_vecs, word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence_no_padding(s, vocab2index):\n",
    "    return np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in s.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlickrStyle7kDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.x = [(encode_sentence_no_padding(pair[0], vocab2index),\n",
    "                    encode_sentence_no_padding(pair[1], vocab2index)) for pair in X]\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        return x, self.y[idx]\n",
    "    \n",
    "train_ds = FlickrStyle7kDataset(X_train, y_train)\n",
    "valid_ds = FlickrStyle7kDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([12, 17,  8, 24, 19,  3,  2,  6,  4, 22, 15, 10, 13, 25, 23]),\n",
       "  array([24,  9, 14, 20, 15, 18, 22,  7, 11, 16, 21, 22,  5, 23])),\n",
       " array(['1341787777_4f1ebb1793.jpg'], dtype=object))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Padding and Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    Creates mini-batch tensors from the list of nested\n",
    "    tuples ((q1, q2), labels).\n",
    "    \"\"\"\n",
    "    question, labels = zip(*data)\n",
    "    q1, q2 = zip(*question)\n",
    "    q1 = [torch.Tensor(s) for s in q1]\n",
    "    q2 = [torch.Tensor(s) for s in q2]\n",
    "\n",
    "    # stack labels\n",
    "    #labels = torch.Tensor(labels)\n",
    "    \n",
    "    # Merge sentences\n",
    "    length1 = [len(s) for s in q1]\n",
    "    length2 = [len(s) for s in q2]\n",
    "   \n",
    "    # Padding\n",
    "    sents1 = pad_sequence(q1, batch_first=True, padding_value=0)\n",
    "    sents2 = pad_sequence(q2, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return sents1, sents2, length1, length2 #, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[12., 17.,  8., 24., 19.,  3.,  2.,  6.,  4., 22., 15., 10., 13., 25.,\n",
       "          23.],\n",
       "         [12., 26.,  4., 43., 34., 38., 25., 48., 39., 36., 29., 37., 28., 33.,\n",
       "          23.],\n",
       "         [12., 26., 57., 22., 55., 61., 62., 28., 49., 52., 23.,  0.,  0.,  0.,\n",
       "           0.]]),\n",
       " tensor([[24.,  9., 14., 20., 15., 18., 22.,  7., 11., 16., 21., 22.,  5., 23.,\n",
       "           0.,  0.,  0.,  0.],\n",
       "         [12., 40., 31., 12., 47., 27., 41., 12., 45., 35.,  4., 44., 30., 32.,\n",
       "          46., 28., 42., 23.],\n",
       "         [58., 53., 56., 12., 51., 62., 58., 52., 31., 63., 12., 54., 59., 50.,\n",
       "          62., 28., 60., 23.]]),\n",
       " [15, 15, 11],\n",
       " [14, 18, 18])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_fn([train_ds[0], train_ds[1], train_ds[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
